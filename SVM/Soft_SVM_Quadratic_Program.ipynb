{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Soft_SVM_Quadratic_Program.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1UqBtAvhEHD"
      },
      "source": [
        "# Soft SVM (Support vector machine) using convex Quadratic program \n",
        "\n",
        "## Step 1: Import All required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDvNdYa9CjLj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cvxopt import matrix as cvxopt_matrix\n",
        "from cvxopt import solvers as cvxopt_solvers"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwbCo4pnhNcv"
      },
      "source": [
        "## Step 2: Read CSV file (For this i have uploded the file on google colab) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKpaEb3HDOUT",
        "outputId": "f9e123f0-48b0-4d42-b9a5-06e641eb0988"
      },
      "source": [
        "df = pd.read_csv('file.csv')\n",
        "print(df.shape,df)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2665, 6)       Temperature   Humidity       Light          CO2  HumidityRatio  Occupancy\n",
            "0       23.700000  26.272000  585.200000   749.200000       0.004764          1\n",
            "1       23.718000  26.290000  578.400000   760.400000       0.004773          1\n",
            "2       23.730000  26.230000  572.666667   769.666667       0.004765          1\n",
            "3       23.722500  26.125000  493.750000   774.750000       0.004744          1\n",
            "4       23.754000  26.200000  488.600000   779.000000       0.004767          1\n",
            "...           ...        ...         ...          ...            ...        ...\n",
            "2660    24.290000  25.700000  808.000000  1150.250000       0.004829          1\n",
            "2661    24.330000  25.736000  809.800000  1129.200000       0.004848          1\n",
            "2662    24.330000  25.700000  817.000000  1125.800000       0.004841          1\n",
            "2663    24.356667  25.700000  813.000000  1123.000000       0.004849          1\n",
            "2664    24.408333  25.681667  798.000000  1124.000000       0.004860          1\n",
            "\n",
            "[2665 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pqvpAIihVza"
      },
      "source": [
        "## Step 3: Store the features and target in X , Y seperately and since target has value 0,1 change label 0 to -1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poQAQWxkDlIQ",
        "outputId": "dee00e70-9cf7-4c13-d9d6-63c9f06f15d8"
      },
      "source": [
        "X = df.iloc[:,:-1].values\n",
        "Y = df.iloc[:,-1:].values\n",
        "print(X.shape,X)\n",
        "Y[Y==0]=-1\n",
        "print(Y.shape,Y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2665, 5) [[2.37000000e+01 2.62720000e+01 5.85200000e+02 7.49200000e+02\n",
            "  4.76416302e-03]\n",
            " [2.37180000e+01 2.62900000e+01 5.78400000e+02 7.60400000e+02\n",
            "  4.77266099e-03]\n",
            " [2.37300000e+01 2.62300000e+01 5.72666667e+02 7.69666667e+02\n",
            "  4.76515255e-03]\n",
            " ...\n",
            " [2.43300000e+01 2.57000000e+01 8.17000000e+02 1.12580000e+03\n",
            "  4.84075873e-03]\n",
            " [2.43566667e+01 2.57000000e+01 8.13000000e+02 1.12300000e+03\n",
            "  4.84855928e-03]\n",
            " [2.44083333e+01 2.56816667e+01 7.98000000e+02 1.12400000e+03\n",
            "  4.86020770e-03]]\n",
            "(2665, 1) [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjSE8T5ihdNM"
      },
      "source": [
        "## Step 4: Processing the Data and Splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZfy-oNAEACo",
        "outputId": "9fe0c098-342b-48ab-e497-1a08c5cb9846"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.83168317, 0.44513204, 0.34479305, 0.33003334, 0.70421197],\n",
              "       [0.8359604 , 0.44705255, 0.34078657, 0.34152347, 0.70830847],\n",
              "       [0.83881188, 0.44065084, 0.33740855, 0.35103018, 0.70468898],\n",
              "       ...,\n",
              "       [0.98138614, 0.38410243, 0.48136692, 0.71638882, 0.74113545],\n",
              "       [0.98772277, 0.38410243, 0.47901016, 0.71351629, 0.74489576],\n",
              "       [1.        , 0.38214635, 0.47017234, 0.71454219, 0.75051096]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWkz0kv_mRqT"
      },
      "source": [
        "A. Split the data in 70,30 for training and testing the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8yozto7mOKz",
        "outputId": "97bd8164-a53a-41eb-b10d-1a35124b89bf"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, Y, test_size=0.3, random_state=1)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1865, 5) (800, 5) (1865, 1) (800, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgkjzYQmheUB"
      },
      "source": [
        "B. Split the data in 80,20 for training and testing the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miV86CSwhjt3",
        "outputId": "fb4c275e-fba4-4574-99eb-6b44c9967d8c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2132, 5) (533, 5) (2132, 1) (533, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOQq3SrIiBVo"
      },
      "source": [
        "C. Split the data in 90,10 for training and testing the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDNx6FeziGfn",
        "outputId": "e9a1b0e6-2fd1-4408-b41e-cf71d0e66598"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2398, 5) (267, 5) (2398, 1) (267, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgyzBmnHiJKA"
      },
      "source": [
        "## Step 5: Optimizing the weight vector w using the cvxopt_solvers\n",
        "## Here we need to change the variables as:\n",
        "### max(a) 1/2*a^T*H^T*a - 1^T*a\n",
        "### such that -a<=0 and y^T*a=0\n",
        "### where for the Quadratic solver the respective variables are:\n",
        "### X=a , P=H (matrix of size m×m), q=-1 ( a vector of size m×1), G=-a (matrix of size 2m×m, such that a diagonal matrix of -1s of size m×m is concatenated vertically with another diagonal matrix of 1s of size m×m) , h=0 (a vector of size 2m×1, with zeros in the first m cells and C in the other m cells) , A=y (the label vector of size m×1) , b=0 , H = ghram matrix\n",
        "## Also for regularization c=10 is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGifnzNfEFEA"
      },
      "source": [
        "#Initializing values and computing H. Note the 1.0 to force to float type\n",
        "c=10\n",
        "samples,features = X_train.shape\n",
        "y = y_train.reshape(-1,1) * 1.0\n",
        "X_dash = y*X_train\n",
        "H = np.dot(X_dash , X_dash.T) * 1.0\n",
        "\n",
        "#Converting into cvxopt format\n",
        "P = cvxopt_matrix(H)\n",
        "q = cvxopt_matrix(-np.ones((samples, 1)))\n",
        "G = cvxopt_matrix(np.vstack((np.eye(samples)*-1,np.eye(samples))))\n",
        "h = cvxopt_matrix(np.hstack((np.zeros(samples), np.ones(samples)))*c)\n",
        "A = cvxopt_matrix(y.reshape(1, -1))\n",
        "b = cvxopt_matrix(np.zeros(1))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJCY02A8nK0F"
      },
      "source": [
        "## Step 6: Calculating optimized value of w using the defined solver and checking for alphas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWaOI7nyEKOb",
        "outputId": "863f0748-63a9-47f9-9fe5-81505aadd3c5"
      },
      "source": [
        "sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
        "alphas = np.array(sol['x'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -1.4534e+03 -5.5336e+05  4e+06  3e+00  7e-08\n",
            " 1: -1.1295e+03 -3.4788e+05  6e+05  3e-01  6e-08\n",
            " 2: -8.6375e+02 -5.4004e+04  7e+04  2e-02  5e-08\n",
            " 3: -8.4338e+02 -3.7391e+04  5e+04  1e-02  5e-08\n",
            " 4: -8.5219e+02 -1.4800e+04  2e+04  4e-03  5e-08\n",
            " 5: -9.4221e+02 -5.5628e+03  5e+03  8e-04  6e-08\n",
            " 6: -9.9280e+02 -2.1240e+03  1e+03  2e-04  6e-08\n",
            " 7: -1.0082e+03 -2.1331e+03  1e+03  2e-04  6e-08\n",
            " 8: -9.9800e+02 -2.0541e+03  1e+03  1e-04  5e-08\n",
            " 9: -1.0056e+03 -1.8043e+03  8e+02  5e-05  5e-08\n",
            "10: -1.0193e+03 -1.8131e+03  8e+02  5e-05  5e-08\n",
            "11: -1.0284e+03 -1.4854e+03  5e+02  2e-05  5e-08\n",
            "12: -1.0370e+03 -1.4928e+03  5e+02  2e-05  5e-08\n",
            "13: -1.0266e+03 -1.4549e+03  4e+02  1e-05  5e-08\n",
            "14: -1.0318e+03 -1.3898e+03  4e+02  8e-06  5e-08\n",
            "15: -1.0297e+03 -1.3853e+03  4e+02  7e-06  5e-08\n",
            "16: -1.0432e+03 -1.3847e+03  3e+02  4e-06  5e-08\n",
            "17: -1.0519e+03 -1.2056e+03  2e+02  1e-06  5e-08\n",
            "18: -1.0563e+03 -1.2098e+03  2e+02  9e-07  5e-08\n",
            "19: -1.0507e+03 -1.2039e+03  2e+02  9e-07  6e-08\n",
            "20: -1.0527e+03 -1.2059e+03  2e+02  9e-07  6e-08\n",
            "21: -1.0564e+03 -1.2067e+03  2e+02  9e-07  5e-08\n",
            "22: -1.0565e+03 -1.2038e+03  1e+02  7e-07  5e-08\n",
            "23: -1.0667e+03 -1.1989e+03  1e+02  5e-07  5e-08\n",
            "24: -1.0776e+03 -1.1783e+03  1e+02  3e-07  5e-08\n",
            "25: -1.0854e+03 -1.1610e+03  8e+01  2e-07  5e-08\n",
            "26: -1.0897e+03 -1.1493e+03  6e+01  2e-07  5e-08\n",
            "27: -1.0967e+03 -1.1346e+03  4e+01  5e-08  6e-08\n",
            "28: -1.0994e+03 -1.1306e+03  3e+01  4e-08  5e-08\n",
            "29: -1.1014e+03 -1.1259e+03  2e+01  2e-08  5e-08\n",
            "30: -1.1029e+03 -1.1226e+03  2e+01  1e-08  6e-08\n",
            "31: -1.1043e+03 -1.1197e+03  2e+01  5e-09  6e-08\n",
            "32: -1.1074e+03 -1.1153e+03  8e+00  3e-14  7e-08\n",
            "33: -1.1088e+03 -1.1137e+03  5e+00  5e-14  6e-08\n",
            "34: -1.1103e+03 -1.1121e+03  2e+00  1e-14  6e-08\n",
            "35: -1.1111e+03 -1.1113e+03  2e-01  4e-14  7e-08\n",
            "36: -1.1112e+03 -1.1112e+03  1e-02  3e-14  7e-08\n",
            "37: -1.1112e+03 -1.1112e+03  2e-04  2e-14  7e-08\n",
            "Optimal solution found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mo2hIzrdZi7"
      },
      "source": [
        "## Here W = alphai*yi*xi\n",
        "## Also b = 1/n(sum(y[i]-W*xi))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj0UDZLKFSpe",
        "outputId": "3e982e12-40dc-4dbb-f930-20747385a4a1"
      },
      "source": [
        "# w parameters calculated using the alphas which we get after the solver gives output.\n",
        "w = np.dot((y_train * alphas).T,X_train).reshape(-1,1)\n",
        "\n",
        "# Computing b\n",
        "is_sv = (alphas > 1e-4).flatten()\n",
        "b = y[is_sv] - np.dot(X_train[is_sv], w)\n",
        "b = sum(b)/len(b)\n",
        "\n",
        "# Display results\n",
        "print('Alphas = ',alphas[alphas > 1e-4])\n",
        "print('w = ', w.flatten())\n",
        "print('b = ', b)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alphas =  [9.99999477 9.99999998 9.99998669 9.99999859 9.99999999 9.99999999\n",
            " 9.99999937 9.99999998 9.99999995 9.99999893 9.99999612 9.99999999\n",
            " 9.99999998 9.99999998 9.99999999 9.99999998 9.99999998 9.99999923\n",
            " 9.99999998 9.99999998 9.99999877 9.99999999 9.9999991  9.99999958\n",
            " 9.99999998 9.99999784 9.99999937 9.99999998 9.99999998 9.99999816\n",
            " 9.99999902 9.99999999 9.99999999 9.99999065 9.99999859 9.99999894\n",
            " 9.99999932 9.99999999 9.99999999 9.99999998 9.99999998 9.9999989\n",
            " 9.99999998 9.99999615 9.99999931 9.99999398 9.99999756 9.99999998\n",
            " 9.99999998 9.99999999 9.99999998 9.99999914 9.99999999 9.99999998\n",
            " 9.99999998 9.9999995  7.06180829 9.99999998 9.99999949 9.99999895\n",
            " 9.99999959 9.44546083 9.9999989  9.99999937 9.99999828 8.98581196\n",
            " 9.99999878 9.99999844 9.99997247 9.99997743 9.99999824 9.99999997\n",
            " 9.99999999 9.99999934 9.99999998 9.99999998 9.99999998 9.99999999\n",
            " 9.99999999 9.99999937 9.99995924 9.99999998 9.99999813 9.99999862\n",
            " 9.99999933 9.99999999 9.99999999 9.99999964 5.61581529 9.9999993\n",
            " 9.99999834 9.99999914 9.99999619 9.99999998 9.99999709 9.99999515\n",
            " 9.999995   9.99998614 9.99999998 9.99999999 0.12258096 9.99999996\n",
            " 9.99999998 9.99999998 9.99999795 9.99999918 9.99999946 9.99999896\n",
            " 9.99999955 9.99999999 9.99999996 9.9999996  9.99999999]\n",
            "w =  [ 0.16556828  0.25891565  0.00754959 -0.00292566 -0.00026248]\n",
            "b =  [-10.96275425]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30zGy2mKZyQ8",
        "outputId": "f27275e0-758e-47da-b52a-2daab2686350"
      },
      "source": [
        "X_Support_vectors = X_train[is_sv]\n",
        "y_support_vectors = y[is_sv]\n",
        "print(alphas,'\\n',\"Support vectors are : = \",X_Support_vectors,'\\n','\\n',\"Number of support vectors = \",len(X_Support_vectors))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.43688822e-08]\n",
            " [3.49668905e-07]\n",
            " [2.79959566e-08]\n",
            " ...\n",
            " [3.40195086e-07]\n",
            " [2.67551743e-08]\n",
            " [2.85867082e-07]] \n",
            " Support vectors are : =  [[2.25600000e+01 2.50200000e+01 4.33000000e+02 8.30750000e+02\n",
            "  4.23128418e-03]\n",
            " [2.25400000e+01 2.51600000e+01 4.27400000e+02 8.53600000e+02\n",
            "  4.24992107e-03]\n",
            " [2.27000000e+01 3.12900000e+01 4.33000000e+02 1.39250000e+03\n",
            "  5.34630672e-03]\n",
            " [2.26000000e+01 2.50000000e+01 4.33000000e+02 8.37000000e+02\n",
            "  4.23823119e-03]\n",
            " [2.22000000e+01 2.60000000e+01 6.08250000e+02 9.46000000e+02\n",
            "  4.30227873e-03]\n",
            " [2.12000000e+01 2.52900000e+01 4.64000000e+02 7.77750000e+02\n",
            "  3.93429348e-03]\n",
            " [2.23900000e+01 2.47170833e+01 4.19000000e+02 7.72925000e+02\n",
            "  4.13646442e-03]\n",
            " [2.24175000e+01 2.47225000e+01 4.19000000e+02 7.89750000e+02\n",
            "  4.14434755e-03]\n",
            " [2.03900000e+01 2.37000000e+01 3.11750000e+02 4.74750000e+02\n",
            "  3.50518545e-03]\n",
            " [2.26000000e+01 2.51666667e+01 4.33000000e+02 8.54333333e+02\n",
            "  4.26667988e-03]\n",
            " [2.26000000e+01 2.50000000e+01 4.33000000e+02 8.32000000e+02\n",
            "  4.23823119e-03]\n",
            " [2.32000000e+01 2.55000000e+01 6.29000000e+02 8.99000000e+02\n",
            "  4.48477799e-03]\n",
            " [2.25000000e+01 2.48900000e+01 4.19000000e+02 8.13800000e+02\n",
            "  4.19373268e-03]\n",
            " [2.26000000e+01 2.52000000e+01 4.22500000e+02 8.53000000e+02\n",
            "  4.27236993e-03]\n",
            " [2.06000000e+01 2.40833333e+01 4.13000000e+02 5.07333333e+02\n",
            "  3.60893584e-03]\n",
            " [2.06000000e+01 2.41750000e+01 4.07500000e+02 5.22250000e+02\n",
            "  3.62275228e-03]\n",
            " [2.25000000e+01 2.49120000e+01 4.19000000e+02 8.14200000e+02\n",
            "  4.19746449e-03]\n",
            " [2.26000000e+01 2.51000000e+01 4.25400000e+02 8.32400000e+02\n",
            "  4.25530009e-03]\n",
            " [2.03100000e+01 2.32000000e+01 4.16200000e+02 4.66000000e+02\n",
            "  3.41382178e-03]\n",
            " [2.25250000e+01 2.51000000e+01 4.26000000e+02 8.34250000e+02\n",
            "  4.23582915e-03]\n",
            " [2.25200000e+01 2.49760000e+01 4.30200000e+02 8.24000000e+02\n",
            "  4.21347257e-03]\n",
            " [2.32000000e+01 2.55166667e+01 5.57666667e+02 8.95333333e+02\n",
            "  4.48773037e-03]\n",
            " [2.26000000e+01 2.50428571e+01 4.33000000e+02 8.45333333e+02\n",
            "  4.24554632e-03]\n",
            " [2.23900000e+01 2.46250000e+01 4.19000000e+02 7.73750000e+02\n",
            "  4.12095195e-03]\n",
            " [2.25400000e+01 2.51400000e+01 4.21800000e+02 8.45600000e+02\n",
            "  4.24651969e-03]\n",
            " [2.25000000e+01 2.48650000e+01 4.33000000e+02 8.16500000e+02\n",
            "  4.18949204e-03]\n",
            " [2.26000000e+01 2.51500000e+01 4.28200000e+02 8.47400000e+02\n",
            "  4.26383489e-03]\n",
            " [2.11333333e+01 2.48233333e+01 4.44000000e+02 7.47333333e+02\n",
            "  3.84537695e-03]\n",
            " [2.25000000e+01 2.48566667e+01 4.19000000e+02 8.02333333e+02\n",
            "  4.18807851e-03]\n",
            " [2.09266667e+01 2.47900000e+01 4.29000000e+02 7.09000000e+02\n",
            "  3.79142217e-03]\n",
            " [2.23900000e+01 2.49120000e+01 4.18600000e+02 7.82800000e+02\n",
            "  4.16930286e-03]\n",
            " [2.23900000e+01 2.72000000e+01 5.75000000e+02 1.05050000e+03\n",
            "  4.55502956e-03]\n",
            " [2.32000000e+01 2.56500000e+01 6.38000000e+02 9.38250000e+02\n",
            "  4.51135038e-03]\n",
            " [2.32000000e+01 2.55800000e+01 1.76000000e+02 9.28800000e+02\n",
            "  4.49894965e-03]\n",
            " [2.32675000e+01 2.58650000e+01 1.93000000e+02 9.94250000e+02\n",
            "  4.56817107e-03]\n",
            " [2.26000000e+01 2.52000000e+01 4.35500000e+02 8.64000000e+02\n",
            "  4.27236993e-03]\n",
            " [2.26666667e+01 2.56000000e+01 4.29000000e+02 8.92000000e+02\n",
            "  4.35838319e-03]\n",
            " [2.10000000e+01 2.53900000e+01 4.44000000e+02 7.20750000e+02\n",
            "  3.90142139e-03]\n",
            " [2.32000000e+01 2.57920000e+01 6.27600000e+02 9.19800000e+02\n",
            "  4.53650765e-03]\n",
            " [2.25000000e+01 2.50400000e+01 4.21800000e+02 8.26400000e+02\n",
            "  4.21917772e-03]\n",
            " [2.02900000e+01 2.27900000e+01 2.17200000e+02 4.41600000e+02\n",
            "  3.34900176e-03]\n",
            " [2.08900000e+01 2.48500000e+01 4.29000000e+02 7.16200000e+02\n",
            "  3.79204009e-03]\n",
            " [2.24780000e+01 2.48700000e+01 4.19000000e+02 8.04600000e+02\n",
            "  4.18470411e-03]\n",
            " [2.26800000e+01 2.57720000e+01 4.32000000e+02 9.02400000e+02\n",
            "  4.39144943e-03]\n",
            " [2.26000000e+01 2.50000000e+01 4.28200000e+02 8.32600000e+02\n",
            "  4.23823119e-03]\n",
            " [2.28900000e+01 3.08300000e+01 4.42000000e+02 1.38860000e+03\n",
            "  5.32858902e-03]\n",
            " [2.26000000e+01 2.50500000e+01 4.31750000e+02 8.34750000e+02\n",
            "  4.24676552e-03]\n",
            " [2.25400000e+01 2.51600000e+01 4.24600000e+02 8.52000000e+02\n",
            "  4.24992107e-03]\n",
            " [2.25000000e+01 2.50000000e+01 4.19000000e+02 8.29600000e+02\n",
            "  4.21239217e-03]\n",
            " [2.22900000e+01 2.59633333e+01 6.06666667e+02 9.50333333e+02\n",
            "  4.31993870e-03]\n",
            " [2.06000000e+01 2.42000000e+01 4.06600000e+02 5.25600000e+02\n",
            "  3.62652051e-03]\n",
            " [2.08900000e+01 2.49175000e+01 4.29000000e+02 7.25000000e+02\n",
            "  3.80240337e-03]\n",
            " [2.22000000e+01 2.76428571e+01 5.35714286e+02 1.13785714e+03\n",
            "  4.57612602e-03]\n",
            " [2.02900000e+01 2.30000000e+01 4.19000000e+02 4.53000000e+02\n",
            "  3.38002906e-03]\n",
            " [2.24560000e+01 2.48300000e+01 4.19000000e+02 8.07800000e+02\n",
            "  4.17230818e-03]\n",
            " [2.26000000e+01 2.51500000e+01 4.30750000e+02 8.59000000e+02\n",
            "  4.26383489e-03]\n",
            " [2.26500000e+01 2.54200000e+01 4.38000000e+02 8.80750000e+02\n",
            "  4.32311961e-03]\n",
            " [2.23900000e+01 2.47000000e+01 4.19000000e+02 7.90600000e+02\n",
            "  4.13358648e-03]\n",
            " [2.26400000e+01 2.56960000e+01 4.29000000e+02 9.04400000e+02\n",
            "  4.36771761e-03]\n",
            " [2.03900000e+01 2.36600000e+01 3.97400000e+02 5.01000000e+02\n",
            "  3.49923624e-03]\n",
            " [2.26000000e+01 2.55750000e+01 4.29000000e+02 8.97000000e+02\n",
            "  4.33639010e-03]\n",
            " [2.03900000e+01 2.33400000e+01 4.03500000e+02 4.79750000e+02\n",
            "  3.45164666e-03]\n",
            " [2.26000000e+01 2.50214286e+01 4.33000000e+02 8.41166667e+02\n",
            "  4.24188873e-03]\n",
            " [2.25250000e+01 2.48900000e+01 4.26000000e+02 8.14250000e+02\n",
            "  4.20015063e-03]\n",
            " [2.08900000e+01 2.48900000e+01 4.29000000e+02 7.16166667e+02\n",
            "  3.79818125e-03]\n",
            " [2.27000000e+01 3.13785714e+01 4.33000000e+02 1.39800000e+03\n",
            "  5.36157076e-03]\n",
            " [2.25400000e+01 2.48900000e+01 4.33000000e+02 8.25000000e+02\n",
            "  4.20400556e-03]\n",
            " [2.26000000e+01 2.50000000e+01 4.33000000e+02 8.36250000e+02\n",
            "  4.23823119e-03]\n",
            " [2.32000000e+01 2.56000000e+01 1.76000000e+02 9.33200000e+02\n",
            "  4.50249267e-03]\n",
            " [2.25750000e+01 2.50750000e+01 4.33000000e+02 8.34500000e+02\n",
            "  4.24454028e-03]\n",
            " [2.26000000e+01 2.50800000e+01 4.29200000e+02 8.32400000e+02\n",
            "  4.25188624e-03]\n",
            " [2.32600000e+01 2.58566667e+01 3.38333333e+02 9.97333333e+02\n",
            "  4.56460472e-03]\n",
            " [2.12150000e+01 2.52916667e+01 4.62333333e+02 7.73833333e+02\n",
            "  3.93820097e-03]\n",
            " [2.26000000e+01 2.51000000e+01 4.33000000e+02 8.54750000e+02\n",
            "  4.25530009e-03]\n",
            " [2.03150000e+01 2.31000000e+01 4.19000000e+02 4.59250000e+02\n",
            "  3.40008274e-03]\n",
            " [2.25000000e+01 2.48900000e+01 4.19000000e+02 8.11000000e+02\n",
            "  4.19373268e-03]\n",
            " [2.25000000e+01 2.48900000e+01 4.19000000e+02 8.13500000e+02\n",
            "  4.19373268e-03]\n",
            " [2.06000000e+01 2.41000000e+01 4.14600000e+02 5.14600000e+02\n",
            "  3.61144788e-03]\n",
            " [2.10000000e+01 2.52900000e+01 4.47200000e+02 7.13000000e+02\n",
            "  3.88595942e-03]\n",
            " [2.03900000e+01 2.35000000e+01 3.99500000e+02 4.98750000e+02\n",
            "  3.47544055e-03]\n",
            " [2.32000000e+01 2.55000000e+01 1.71000000e+02 9.12750000e+02\n",
            "  4.48477799e-03]\n",
            " [2.23900000e+01 2.47000000e+01 4.19000000e+02 7.82200000e+02\n",
            "  4.13358648e-03]\n",
            " [2.26200000e+01 2.54760000e+01 4.36200000e+02 8.87200000e+02\n",
            "  4.32477212e-03]\n",
            " [2.26000000e+01 2.50600000e+01 4.29200000e+02 8.32400000e+02\n",
            "  4.24847242e-03]\n",
            " [2.23900000e+01 2.47225000e+01 4.19000000e+02 7.72250000e+02\n",
            "  4.13737694e-03]\n",
            " [2.23900000e+01 2.72900000e+01 6.03600000e+02 1.06400000e+03\n",
            "  4.57021209e-03]\n",
            " [2.10000000e+01 2.52900000e+01 4.56800000e+02 7.14800000e+02\n",
            "  3.88595942e-03]\n",
            " [2.26000000e+01 2.50800000e+01 4.24600000e+02 8.45400000e+02\n",
            "  4.25188624e-03]\n",
            " [2.32000000e+01 2.55500000e+01 1.71000000e+02 9.18000000e+02\n",
            "  4.49363520e-03]\n",
            " [2.32900000e+01 2.58900000e+01 1.93000000e+02 9.90166667e+02\n",
            "  4.57888337e-03]\n",
            " [2.26000000e+01 2.50400000e+01 4.32200000e+02 8.37200000e+02\n",
            "  4.24505864e-03]\n",
            " [2.08900000e+01 2.47900000e+01 4.29000000e+02 7.13800000e+02\n",
            "  3.78282858e-03]\n",
            " [2.26000000e+01 2.50250000e+01 4.28250000e+02 8.21500000e+02\n",
            "  4.24249833e-03]\n",
            " [2.24560000e+01 2.48100000e+01 4.19000000e+02 7.94400000e+02\n",
            "  4.16892496e-03]\n",
            " [2.32000000e+01 2.55500000e+01 1.77250000e+02 9.24000000e+02\n",
            "  4.49363520e-03]\n",
            " [2.25250000e+01 2.49450000e+01 4.33000000e+02 8.22250000e+02\n",
            "  4.20949462e-03]\n",
            " [2.25600000e+01 2.48100000e+01 4.33000000e+02 8.12200000e+02\n",
            "  4.19553025e-03]\n",
            " [2.25600000e+01 2.49120000e+01 4.33000000e+02 8.19800000e+02\n",
            "  4.21289593e-03]\n",
            " [2.26000000e+01 2.52000000e+01 4.23666667e+02 8.53000000e+02\n",
            "  4.27236993e-03]\n",
            " [2.09560000e+01 2.53900000e+01 4.44000000e+02 7.17800000e+02\n",
            "  3.89081614e-03]\n",
            " [2.26000000e+01 2.53900000e+01 4.43400000e+02 8.89200000e+02\n",
            "  4.30480518e-03]\n",
            " [2.23900000e+01 2.50925000e+01 3.10250000e+02 8.09000000e+02\n",
            "  4.19971552e-03]\n",
            " [2.02900000e+01 2.32000000e+01 4.19000000e+02 4.70400000e+02\n",
            "  3.40958173e-03]\n",
            " [2.24175000e+01 2.47475000e+01 4.19000000e+02 7.96750000e+02\n",
            "  4.14856637e-03]\n",
            " [2.26000000e+01 2.55250000e+01 4.33500000e+02 8.82500000e+02\n",
            "  4.32785332e-03]\n",
            " [2.27000000e+01 2.58150000e+01 4.32750000e+02 9.20250000e+02\n",
            "  4.40420735e-03]\n",
            " [2.23900000e+01 2.47540000e+01 4.16200000e+02 7.71800000e+02\n",
            "  4.14268366e-03]\n",
            " [2.03900000e+01 2.37000000e+01 3.98333333e+02 5.07000000e+02\n",
            "  3.50518545e-03]\n",
            " [2.03900000e+01 2.34340000e+01 3.97400000e+02 4.94200000e+02\n",
            "  3.46562535e-03]\n",
            " [2.10000000e+01 2.53900000e+01 4.44000000e+02 7.18000000e+02\n",
            "  3.90142139e-03]\n",
            " [2.31857143e+01 2.55285714e+01 2.68714286e+02 8.99285714e+02\n",
            "  4.48593616e-03]\n",
            " [2.32900000e+01 2.59783333e+01 1.97166667e+02 9.96500000e+02\n",
            "  4.59462133e-03]\n",
            " [2.23900000e+01 2.72675000e+01 5.87500000e+02 1.06525000e+03\n",
            "  4.56641639e-03]] \n",
            " \n",
            " Number of support vectors =  113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDUC3aBjnZDO"
      },
      "source": [
        "## Step 7: Creating target Array and calculating the target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjmcLnrGVuMd",
        "outputId": "af427577-3cd3-418c-ee85-06d97b87a64b"
      },
      "source": [
        "print(X_test.shape,w.shape)\n",
        "target = np.where(np.dot(X_test,w)+b>=0.0,1,-1)\n",
        "t = np.where(np.dot(X_train,w)+b>=0.0,1,-1)\n",
        "print(target.flatten(),'\\n',t.flatten(),'\\n',y_test.flatten())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(267, 5) (5, 1)\n",
            "[ 1 -1 -1 -1 -1 -1 -1  1  1  1 -1  1 -1 -1 -1 -1  1  1  1 -1  1 -1  1 -1\n",
            " -1  1 -1 -1  1 -1  1 -1  1  1  1  1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1\n",
            "  1 -1 -1 -1  1 -1  1  1 -1  1 -1  1  1 -1 -1 -1  1 -1 -1  1 -1 -1  1  1\n",
            " -1 -1  1 -1 -1  1  1 -1 -1  1 -1  1 -1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1\n",
            " -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1  1  1  1  1 -1 -1 -1  1 -1 -1\n",
            " -1 -1  1  1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1 -1  1\n",
            "  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1  1  1  1 -1\n",
            " -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1  1 -1  1 -1\n",
            "  1 -1  1  1 -1 -1  1  1 -1  1  1  1 -1  1  1  1 -1 -1  1  1 -1  1 -1  1\n",
            "  1 -1  1  1 -1 -1  1 -1  1 -1 -1  1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1\n",
            " -1  1 -1 -1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1\n",
            " -1 -1  1] \n",
            " [-1  1 -1 ...  1 -1  1] \n",
            " [ 1 -1 -1 -1 -1 -1 -1  1  1  1 -1  1 -1 -1 -1 -1  1  1  1 -1  1 -1  1 -1\n",
            " -1  1 -1 -1  1 -1  1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1\n",
            "  1 -1 -1 -1  1 -1 -1  1 -1  1 -1  1  1 -1 -1 -1  1 -1 -1  1 -1 -1  1  1\n",
            " -1 -1  1 -1 -1  1  1 -1 -1  1 -1  1 -1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1\n",
            " -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1  1  1  1 -1 -1 -1  1 -1 -1\n",
            " -1 -1  1  1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1 -1  1\n",
            "  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1 -1\n",
            " -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1  1 -1  1 -1\n",
            "  1 -1  1  1 -1 -1  1  1 -1  1  1  1 -1  1  1  1 -1 -1  1 -1 -1  1 -1  1\n",
            "  1 -1  1  1 -1 -1  1 -1  1 -1 -1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1\n",
            " -1  1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1\n",
            " -1 -1  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFR8-UtNm8SP"
      },
      "source": [
        "## Step 8: Checking for Accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs7ja6NHm23v",
        "outputId": "e808ea93-f735-4de0-8309-4f415a2ad770"
      },
      "source": [
        "v1 = 0  \n",
        "v2 = 0\n",
        "c = 0\n",
        "i=0    \n",
        "for c in range( np.size( target ) ) :  \n",
        "  if y_test[c] == target[c] :            \n",
        "    v1 = v1 + 1\n",
        "for i in range( np.size( t ) ) :\n",
        "  if y_train[i] == t[i] :            \n",
        "    v2 = v2 + 1\n",
        "  i = i + 1\n",
        "print(\"Accuracy of Defined Model on test data :\",(v1/c)*100)     \n",
        "print(\"Accuracy of Defined Model on train data:\",(v2/i)*100)   "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Defined Model on test data : 97.74436090225564\n",
            "Accuracy of Defined Model on train data: 98.41534612176814\n"
          ]
        }
      ]
    }
  ]
}